---
layout: post
title: Pix2Pix Image-to-image translation with a conditional GAN
summary: Image-to-image translation is the problem of changing a given image in a specific or controlled way and the aim is to develop a general-purpose solution to image-to-image translation problems.
featured-img: book
mathjax: true
---

# Pix2Pix: Image-to-image translation with a conditional GAN

<img src='assets/img/posts/blog.png' />

### Table of Contents:

1. Introduction
2. Business problem
3. About the data set
4. Prerequisites
5. EDA
6. Data Preprocessing
7. Architecture
8. Building model
9. Training model
10. Flask demo app
11. Future work
12. Reference

### Introduction

Generative Adversarial Networks (GANs) were first introduced in 2014 by Ian Goodfellow et. al. and since then this topic itself opened up a new area of research. Within a few years, the research community came up with plenty of papers. Generative Models had started showing promising results in generating realistic images. They have shown tremendous success in Computer Vision. In recent times, it started showing promising results in Audio, Text as well.

As we know, GANs are generative models. It is relatively different from other deep learning models, which are meant for classification(i.e., classifying images into certain classes), detection(i.e., detecting different objects/types of things in a given image), etc. In GANs, we have two-component, i.e., Generator and Discriminator. The Generator tries to generate valid samples from a constant noisy input. And the Discriminator is trained to discriminate between the real(good) and fake(invalid) input. GANs are pretty similar to a min-max search. Here, Generator is always trying to deceive the Discriminator by classifying its generated sample as real. And Discriminator always tries to organize the generated samples as fake and data from the training set as real...     [Read more](https://medium.datadriveninvestor.com/pix2pix-image-to-image-translation-with-a-conditional-gan-428878c40d3)